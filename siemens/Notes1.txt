1. 
Eureka 

D:\PraiseTheLord\HSBGInfotech\Others\vilas\micro_temp\microservices1\servicediscovery\eureka
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

2. quick overview of microservices design pattrens
--------------------------------------------------------------------------------

In 	microservices architecture
	key challenges 
		maintaining consistency 
			across multiple services. 
	When multiple services must coordinate to complete a transaction
		managing distributed transactions becomes complex. 
		
	manage 
		long-running, 
		distributed transactions, 
			without the need for 
				distributed locks or 
				complex two-phase commit protocols.

1. What is Saga?
	https://www.vinsguru.com/choreography-saga-pattern-with-spring-boot/
	https://github.com/vinsguru/vinsguru-blog-code-samples/tree/master/architectural-pattern/saga-choreography
		
	https://github.com/Dilsh0d/SpringBoot-Microservice-Saga
		kafka 
	A Saga 
		series of transactions 
		that must occur across different services. 
		Each service within the microservices architecture 
			performs a local transaction
			if 
				one of these transactions fails, 
				compensating transactions are triggered to 
					undo the changes made by the preceding services. 
				In other words, 
					Sagas manage distributed transaction consistency 
						by breaking down a large transaction 
							into smaller steps, 
							with rollback steps in case of failure.

2. Saga Pattern Characteristics
	Choreography or Orchestration: 
		Two primary methods for implementing 
			Sagas—Choreography and 
			Orchestration.
	Decentralized Coordination: 
		Sagas eliminate the need for a 
			centralized transaction manager.
	Compensating Actions: 
		If a transaction fails, 
			compensating actions 
				reverse the steps already taken.
	Eventual Consistency: 
		The system aims to achieve a consistent state eventually, even in the face of failures.
3. Saga Types: Choreography and Orchestration
	Choreography-based Saga:

		In a choreography-based Saga
			there is no central coordinator; 
				each service is responsible for 
					publishing and 
					listening 
						to events. 
			Once a service completes 
				its local transaction, 
				it 
					publishes an event, 
						triggering the next service to act.
		Advantages: 
			Simplicity, low coupling.
		Challenges: 
			Harder to 
				track and 
				manage as 
					the number of services grows, 
					harder to debug.
	Orchestration-based Saga:

		In an orchestration-based Saga, 
			there is a central controller, 
				known as the Saga orchestrator, 
				that tells 
					each service 
						what operation 
							to perform and coordinates the entire workflow.
		Advantages: 
			Easier to manage, 
				clearer control flow.
		Challenges: 
			Central orchestration 
				introduces some 
					coupling and 
					complexity, and 
						it can become a single point of failure if not designed properly.

4. Saga Example: Online Order Management
	Imagine an online shopping platform where 
		placing an order 
			involves multiple services: 
				inventory, 
				payment, and 
				delivery. 
			The entire process must succeed for the order to be completed, but if any service fails, the system must roll back the preceding actions. The Saga pattern ensures eventual consistency across these services.

Choreography Example:

	Order Service creates an order and publishes an event.
	Inventory Service receives the event and reserves the items.
	Payment Service processes the payment.
	Delivery Service schedules delivery.

If the Payment Service fails, the Inventory Service compensates by releasing the reserved items, and the Order Service cancels the order.

Orchestration Example:

	The Saga Orchestrator directs the Order Service to create the order.
	The Orchestrator then instructs the Inventory Service to reserve the items.
	It directs the Payment Service to process the payment.
	If any step fails, the orchestrator ensures that compensating actions are taken by the previous services.

5. Advantages of the Saga Pattern
	Scalability: 
		Since Sagas allow services to handle their transactions independently, the system can scale effectively.
	Resilience: 
		By defining compensating actions, the system can handle failures more gracefully, ensuring that inconsistent states are corrected.
	Flexibility: 
		Sagas allow for complex, long-running business processes without requiring distributed locking mechanisms.

6. Challenges in Using Saga
	Complexity of Compensation Logic: 
		Writing compensating transactions can be tricky, and not all operations can be easily undone.
	Eventual Consistency: 
		The system may not be immediately consistent, which could affect user experience or other parts of the system.
	Coordination Complexity: 
		Managing events in choreography or dealing with centralized orchestrators introduces coordination overhead.

7. Best Practices for Implementing Sagas
	Idempotency: 
		Ensure that each transaction and compensating action is idempotent, meaning that they can be executed multiple times without adverse effects.
	Event-Driven Design: 
		Use an event-driven architecture to manage communication between services, especially for the choreography model.
	Monitoring and Observability: 
		Implement logging and monitoring to track the flow of the Saga, especially in the case of failures and retries.
	Error Handling: 
		Proper error handling and fallback mechanisms are critical, as failures can happen at any point in the Saga.
8. Saga vs Two-Phase Commit (2PC)
	Sagas offer a more scalable and flexible alternative to the traditional two-phase commit (2PC) protocol for distributed transactions. While 2PC ensures strict consistency by locking resources until the transaction completes, Sagas allow for eventual consistency and don’t rely on locking, making them more suitable for modern, distributed microservices systems.

9. Real-World Case Study: Travel Booking System
	In a travel booking system, booking a trip often involves coordinating multiple services, such as flights, hotels, and car rentals. Using the Saga pattern, each of these services can act independently:

	Flight Service books a flight.
		Hotel Service books a room.
		Car Rental Service reserves a car.

	If the Car Rental Service fails, the Hotel Service can cancel the room, and the Flight Service can release the seat. Each service can handle its part of the transaction without requiring a central lock, ensuring that the system is eventually consistent.



-----------

1. Introduction to CQRS
	CQRS (Command Query Responsibility Segregation) is a design pattern used in software architecture that separates the responsibilities of reading data (queries) from modifying data (commands). Traditionally, applications follow a CRUD model (Create, Read, Update, Delete), where all operations are performed on the same data model. In CQRS, the application divides these responsibilities into distinct models: one for updating the system's state (commands) and another for querying or reading the system’s data (queries).

	This segregation offers several advantages, particularly in the context of microservices, where scalability, performance optimization, and eventual consistency are critical.


2. CQRS Architecture Overview
	CQRS consists of two primary components:

Command Model:
	Handles 
		write operations, 
		responsible for modifying the system's state.
	Operations include 
		creating, 
		updating, or 
		deleting data.
	These operations are often 
		designed to execute complex business logic.
Query Model:
	Responsible for 
		reading data and 
		answering queries.
	Provides 
		fast and 
		efficient 
			access to the system’s current state.
	Can have 
		different 
			data structures and 
			models 
				optimized specifically for fast reads, 
			which may be very different from the write model.
	In some architectures, CQRS is combined with Event Sourcing, a design pattern where the state of the system is stored as a sequence of events rather than a direct snapshot of the data at any point in time.

3. Command and Query Separation
	The core idea of CQRS is to split the system's data model into two parts:

	Command Side: 
		The commands 
			alter the state of the system by applying changes or events. 
		Commands in CQRS 
			are imperative, 
			meaning 
				they request a specific action and 
				often involve complex business logic. 
			Each command 
				responsible for performing actions such as 
					creating an order, 
					updating a customer profile, or 
					deleting a product.

	Query Side: 
		Queries, 
			used purely for retrieving data. 
		In CQRS, 
			queries can be optimized independently from the command side, 
			focus on 
				performance, 
				scalability, or 
				denormalization of data to optimize for read performance.

4. CQRS in the Context of Microservices
	In a microservices architecture, 
		CQRS fits well 
			independent scaling of 
				read and 
				write workloads
			focus on one aspect of the application — 
				writing or 
				reading data — 
			without needing to handle both simultaneously. 
		flexibilE 
			how each microservice is designed and deployed, 
		allowing for 
			independent scaling, 
			optimization, and 
			versioning of read and write models.

Key Benefits in Microservices:
	Performance and Scalability: 
		The query model can be optimized for performance, using caching, denormalized views, or in-memory databases, while the command model can focus on data integrity and complex business rules.
	Eventual Consistency: 
		Since CQRS often works asynchronously between the command and query sides, it enables eventual consistency, which is suitable for distributed microservices systems.
	Separation of Concerns: 
		By clearly distinguishing the logic for reads and writes, developers can focus on specific concerns for each side (e.g., validation in commands, data retrieval optimization in queries).
5. CQRS with Event Sourcing
	One of the most powerful combinations in a microservices architecture is using CQRS with Event Sourcing. In Event Sourcing:

	Every state change in the system is	 stored as an event.
	Instead of storing the current state of the data, the system stores a history of all the events that have led to the current state.
	In a CQRS architecture, the command side generates events that modify the state, and the query side can build up the current state by replaying these events. This provides a full audit trail of changes and allows for flexible data rebuilding or versioning.

6. Use Cases for CQRS
	Complex Domains: Systems where the business logic for updates is complex and doesn’t easily fit into the CRUD model. CQRS allows a clear separation of business rules from the read operations, simplifying both.

	High Performance Applications: Applications that have vastly different read and write performance needs can use CQRS to optimize each separately.

	Event-Driven Architectures: In systems where business events are essential, and state needs to be rebuilt from historical events, CQRS can work with Event Sourcing to manage these event streams effectively.

7. Challenges and Considerations
	While CQRS offers significant advantages, it also introduces some complexities:

	Increased Complexity: Implementing CQRS can lead to more complexity in the system's architecture, as developers need to maintain separate models for commands and queries.

	Eventual Consistency: In systems using CQRS with asynchronous processing, there may be a delay between the time a command is processed and when the query side reflects the changes. This requires a design that can tolerate eventual consistency.

	Data Synchronization: Keeping the read model in sync with the write model can be tricky, especially in the case of complex workflows or business transactions.

8. CQRS Example: E-Commerce Application
	Consider an e-commerce platform where users can browse products, add them to a cart, and place orders. Here's how CQRS could be applied:

	Command Model:

	A user adds a product to the cart, which triggers a command to update the shopping cart's state.
	When the user places the order, a command is sent to the order service, which validates the request, reserves inventory, processes payment, and creates an order.
	Query Model:

	For the user’s cart, a separate query service retrieves the cart's current contents from a read-optimized data store.
	After the order is placed, the query service provides the user with order status and history by querying the read model, which might be optimized for fast lookups.
	In this scenario, the command side ensures that business rules are followed (e.g., checking inventory before confirming an order), while the query side can quickly return the cart's contents or order status without executing any business logic.

9. CQRS Tools and Frameworks
	Several frameworks and tools support the implementation of CQRS:

	Axon Framework: A popular Java framework that supports CQRS and Event Sourcing.
	Lagom: A microservices framework for Java and Scala that incorporates CQRS and Event Sourcing.
	Kafka: Though not explicitly a CQRS tool, Kafka is often used to handle the event streams in a CQRS architecture.

10. CQRS Best Practices
	Use when necessary: 
		Apply CQRS selectively. It is most beneficial for systems with complex domain logic or where performance requirements differ significantly between reads and writes.

	Ensure idempotency: 
		Commands and events in a CQRS system should be idempotent, ensuring that repeated execution of an event doesn't result in inconsistent state.

	Implement compensating actions: 
		For commands that fail in the middle of processing, make sure compensating actions are defined to maintain system integrity.









--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

3. ELK stack
--------------------------------------------------------------------------------
https://www.javainuse.com/spring/springboot-microservice-elk
	https://github.com/lemoncode21/springboot-logging-elk
	https://www.youtube.com/watch?v=hvYUwUmHB6M&t=569s
	http://localhost:9200/_cat
	http://localhost:9200/_cat/indices
		copy logstash 	
	http://localhost:9200/logstash..../_search 		
	
		spring web 
			refer dependencies 
			refer logback-spring.xml
			controller 
				user Logger 
				
		
	https://github.com/lemoncode21/docker-loging-elk
		docker compose 
			https://github.com/lemoncode21/docker-loging-elk
			https://github.com/lemoncode21/docker-loging-elk/blob/master/docker-compose.yml

The ELK Stack 
	powerful open-source platform 
		used for real-time 
			data collection, 
			analysis, and 
			visualization. 
	It consists of three primary components: 
		Elasticsearch, 
		Logstash, and 
		Kibana.

Elasticsearch:

	Centralized repository: 
		Stores and indexes data 
			from various sources in 
			highly scalable and 
			distributed manner.
	Full-text search: 
		efficient searching and 
		analysis of textual data.
	RESTful API: 
		Allows 
			easy interaction 
				with the data 
					using HTTP requests.
	Schema-less: 
		Supports flexible data structures without 
			requiring a predefined schema.
Logstash:

	Data pipeline: 
		Ingests data from various sources 
			(e.g., files, databases, APIs) and 
			processes it 
				before sending it to Elasticsearch.
	Data transformation: 
		Can 
			filter, 
			enrich, and 
			normalize data 
				using plugins and scripts.
	Data shipping: 
		Sends processed data to 
			Elasticsearch for storage and analysis.
Kibana:

	Visualization layer: 
		Provides a 
			web-based interface for 
				exploring and 
				visualizing data 
					stored in Elasticsearch.
	Dashboards: 
		Allows users to 
			create custom dashboards 
				with 
					charts, 
					graphs, and 
					maps to gain 
						insights into their data.
	Discover: 
		Offers a search interface 
			for exploring data and 
			querying Elasticsearch directly.
	Time-based analysis: 
		Enables analysis of data 
			over time 
				using features like 
					date histograms and 
					trends.

Key features and benefits of the ELK Stack:

	Centralized logging: 
		Collects 
			logs from 
				various sources and 
				stores 
					them in a single location for easy analysis.
	Real-time analytics: 
		Provides 
			near real-time insights 
				into data 
					through 
						dashboards and 
						visualizations.
	Scalability: 
		Can handle 
			large volumes of data and 
				scale horizontally to 
					meet growing demands.
	Flexibility: 
		Supports 
			wide range of data sources and 
				allows for custom data processing.
	Open-source: 
		Free and open-source, 
			providing a cost-effective solution.
	Community support: 
		Benefits from a 
			large and 
			active community of developers and users.
Common use cases of the ELK Stack:

	Log analysis: 
		Monitoring and 
		troubleshooting 
			applications, 
			systems, and 
			networks.
	Security monitoring: 
		Detect 
			security threats and 
			anomalies 
				in network traffic and logs.
	Web analytics: 
		Analyzing 
			website traffic patterns and 
			user behavior.
	Application performance monitoring: 
		Monitoring 
			application performance metrics and 
			identifying bottlenecks.
	IoT data analysis: 
		Collecting and 
		analyzing data from 
			IoT devices and 
			sensors.
Additional components and considerations:

	Beats: 
		Lightweight 
			data shippers 
				can be deployed on various systems to collect data.
	Elastic APM: 
		Monitors 
			application performance and 
			provides detailed insights into code execution.
	Elastic Cloud: 
		A managed service 
			simplifies the 
				deployment and 
				management of the ELK Stack.
	Data retention policies: 
		Implementing 
			appropriate data retention policies 
				to manage 
					storage costs and 
					compliance requirements.
	Security and access control: 
		Ensuring 
			proper security measures and 
			access controls to 
				protect sensitive data.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
	Rest

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
	-> grpc
https://www.javainuse.com/boot3/grpc

What is gRPC
gRPC, 
	short for Google Remote Procedure Call, 
	high-performance 
	open-source framework 
	developed by Google. 
	Facilitates communication between 
		client and server applications, 
		allow them to call methods on each other 
			as if they were making local function calls.

Remote Procedure Call(RPC)
	Remote Procedure Call (RPC) 
		communication protocol 
		inter-process communication 
			between different systems. 
		RPC has some disadvantages 
			tight coupling with 
				specific programming languages and platforms. 
			For example in 
				Java applications 
					use of Java RMI(Remote Method Invocation) 
						for developing the required code skeletons and stubs. 
			While .NET makes use of .NET Remoting for the same.


Representational State Transfer (REST)
-------------------------------------
HTTP Verb	CRUD
POST		Create
GET			Read
PUT			Update/Replace
PATCH		Update/Modify
DELETE		Delete
-------------------------------------

Not the case with gRPC. 
	Using gRPC 
		can create any kind of function calls 
			including 
				synchronous/asynchronous, 
				uni-direction/bidirectional(streams) etc.

	The other major advantage of gRPC 
		REST uses HTTP/1.1 
		gRPC makes use of HTTP/2. 
		HTTP/2 
			allows for lower latency (faster) connections 
				can take advantage of a single connection from client to server. 
		HTTP/2 
			supports 
				bidirectional connectivity and 
				asynchronous connectivity. 
			So it is possible for the server to efficiently make contact with client to send messages



Advantages of gRPC
	gRPC 
		facilitates faster and 
		more efficient communication 
			between systems or services.
	It allows for streamlined and quick exchange of data.
	gRPC supports 
		multiple programming languages, 
		making it developer-friendly.
	Built-in support for 
		authentication and 
		load balancing 
			enhances security and scalability.
	Efficient and secure communication through gRPC 
		enhances performance and 
		user experience in software projects.
	gRPC 
		utilizes Protocol Buffers, a 
			language-agnostic binary serialization format, 
			which enables efficient and compact communication over the network. This results in improved performance and reduced bandwidth consumption.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

rabbitmq


--------------------------------------------------------------------------------

Detailed Overview of RabbitMQ
=============================
RabbitMQ 
	open-source message broker 
	facilitates 
		communication between 
			applications or 
			components 
				by managing message delivery in distributed systems. 
		It provides 
			robust messaging services, 
			ensuring 
				messages are safely 
					queued and 
					routed 
						across multiple systems, 
			allowing them to work asynchronously. 
		
1. What is RabbitMQ?
	message broker 
	supports 
		Advanced Message Queuing Protocol (AMQP), 
			allows different software applications to 
				communicate with each other 
					asynchronously by 
						sending and 
						receiving messages. 
	decouples 
		producer (message sender) and 
		consumer (message receiver), 
		ensure 
			that each message is 
				delivered 
					securely and 
					reliably.

Core Features:
	Message Queuing: 
		Stores and forwards messages in queues.
	Decoupling: 
		Allows systems to communicate independently of each other.
	Routing: 
		Routes messages between 
			producers and 
			consumers using 
				exchanges and bindings.
	Reliability: 
		Messages can persist across system restarts.
	Concurrency: 
		Supports multiple consumers to 
			handle messages concurrently.
2. Architecture of RabbitMQ
	RabbitMQ’s architecture 
		follows a 
			highly scalable and 
			flexible model, 
				supporting complex messaging patterns.

Key Components:
	Producer: 
		creates messages and 
		sends them to exchanges.
	Exchange: 
		The core routing component 
		receives messages from producers 
		routes them to queues based on 
			routing rules (bindings).
	Queue: 
		Stores messages 
			until they are processed by consumers.
	Consumer: 
		Receives and processes messages from the queue.
	Bindings: 
		Links between exchanges and queues. 
		These define how 
			exchange should route messages to the queue.
Connection and Channels: 
	Clients communicate with RabbitMQ through TCP connections, 
	each connection 
		can have multiple logical channels 
			to communicate simultaneously.
Types of Exchanges:
	Direct Exchange: 
		Routes messages based on the exact match 
			between the 
				routing key and 
				binding key.
	Topic Exchange: 
		Routes messages based on wildcard patterns in the routing key.
	Fanout Exchange: 
		Broadcasts all messages to 
			every queue bound to the exchange.
	Headers Exchange: 
		Routes messages based on 
			headers instead of routing keys.
3. RabbitMQ Message Flow
	The flow of messages in RabbitMQ follows a 
		structured process to 
			ensure secure and 
			reliable communication.

Message Publishing: 
	A producer sends a message to an exchange along with a routing key.
Exchange Processing: 
	The exchange uses the routing key and predefined rules (bindings) to determine which queue(s) should receive the message.
Message Enqueueing: 
	The message is placed into the target queue(s).
Message Consumption: 
	Consumers listen to specific queues. They receive messages from the queues and process them.


	RabbitMQ supports acknowledgments to ensure the reliable delivery of messages. After processing, the consumer can acknowledge a message to RabbitMQ, confirming its successful delivery. In case of failure, the message can be requeued or routed to a dead-letter queue.

4. Persistence and Reliability in RabbitMQ
	RabbitMQ ensures message durability and reliability through the following mechanisms:

1. Message Persistence:
	Messages in RabbitMQ can be persisted to disk to ensure they are not lost in the event of a broker crash or system restart. For message persistence, two aspects are important:

	Persistent Messages: Marking messages as persistent ensures they are stored on disk.
	Durable Queues: Declaring queues as durable ensures they survive a broker restart.
2. Acknowledgment and Redelivery:
	Consumers must acknowledge the successful receipt and processing of messages. If a consumer fails to acknowledge a message, RabbitMQ can requeue or redeliver it to another consumer, ensuring no message is lost.

3. High Availability:
	RabbitMQ can run in clustered mode, where multiple RabbitMQ nodes are deployed to ensure high availability. The cluster replicates data between nodes, offering fault tolerance. In case of a node failure, other nodes continue to serve clients without disruption.

5. RabbitMQ vs. Other Messaging Systems
	RabbitMQ is often compared to other message brokers like Apache Kafka, ActiveMQ, and Redis. While each system has its strengths, RabbitMQ is ideal for applications that need strong routing, flexible delivery guarantees, and reliable message queuing.



RabbitMQ vs. Kafka:
	Use Case: RabbitMQ is suited for transactional, low-latency messaging and task queues, while Kafka is used for high-throughput event streaming.
	Message Delivery: RabbitMQ supports complex routing and reliable message delivery, whereas Kafka focuses on event streaming and partitioning for high-scale data ingestion.


RabbitMQ vs. Redis:
	Redis, while supporting basic queuing, is an in-memory key-value store optimized for caching and fast operations, making it less reliable for persistent messaging scenarios.

6. Use Cases for RabbitMQ
	RabbitMQ is highly versatile and can be used in various scenarios:

	1. Microservices Communication:
		RabbitMQ is often used in microservices architectures to enable asynchronous communication between different services, enhancing system resilience and scalability.

	2. Task Queues:
		In systems where background tasks need to be processed (e.g., email notifications, video processing), RabbitMQ acts as an intermediary to ensure tasks are queued and processed by consumers at their own pace.

	3. Event-Driven Architectures:
		RabbitMQ facilitates event-driven systems by allowing services to publish events (e.g., order placed) to a message broker, which routes the events to interested consumers.

	4. Load Balancing:
		RabbitMQ can distribute messages evenly among multiple consumers, allowing systems to scale horizontally as the number of tasks increases.

	5. Data Pipelines:
		In real-time data processing pipelines, RabbitMQ is used to buffer and route data between different stages of processing, ensuring that each stage receives data in the right order.

7. Security and Authentication in RabbitMQ
		Security is an essential aspect of any message broker, and RabbitMQ provides several mechanisms to ensure secure communication:

		1. Authentication:
			RabbitMQ uses a username/password-based authentication system. It also supports external authentication mechanisms like LDAP and OAuth2.

		2. Authorization:
			Once authenticated, RabbitMQ enforces permissions on which exchanges, queues, and virtual hosts a user can access. Role-based access control (RBAC) ensures only authorized users can perform actions like publishing or consuming messages.

		3. Encryption:
			RabbitMQ supports TLS/SSL encryption to secure messages as they traverse between producers, brokers, and consumers.

8. Monitoring and Management of RabbitMQ
RabbitMQ provides a robust management interface and plugins to monitor and manage the system:

	1. Management Plugin:
	The management plugin allows users to view message rates, connections, channels, queues, and exchanges through an intuitive web interface. It also allows administrators to send messages, inspect queues, and control RabbitMQ nodes.

	2. Monitoring Tools:
	RabbitMQ integrates with monitoring tools like Prometheus and Grafana, which allow real-time tracking of performance metrics like queue length, message rates, and system load.

	3. Log Management:
	Logs in RabbitMQ can be configured to capture events at different levels (error, warning, info), providing insights into system behavior and troubleshooting issues.

9. RabbitMQ Best Practices
	To get the best performance and reliability from RabbitMQ, consider the following best practices:

	1. Use Durable Queues and Persistent Messages:
		Ensure that queues and messages are marked as durable and persistent to prevent data loss in case of broker failure.

	2. Load Balancing Consumers:
		Distribute the workload across multiple consumers to ensure messages are processed quickly, especially in high-throughput environments.

	3. Dead-Letter Queues (DLQ):
		Use dead-letter queues to capture messages that cannot be delivered or processed, allowing for later analysis and debugging.

	4. Monitor System Performance:
		Regularly monitor queue lengths, message rates, and consumer performance to identify potential bottlenecks.

	5. Manage Connections Efficiently:
		Close unused connections and channels to conserve resources, especially in environments with many producers and consumers.

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Graphna and prometheus
	wsl hostname -i
	
	docker run -d -v "/d/code1/prometheus:/etc/prometheus/" -p 9090:9090 prom/prometheus:v2.35.0
	docker run -d -v "D:\code1\prometheus\config\:/etc/prometheus/" -p 9090:9090 prom/prometheus:v2.35.0
	 docker exec -it 82 //bin//sh
http://127.0.1.1:8080/actuator/prometheus
	jvm_memory_used_bytes
	jvm_memory_used_bytes{area="heap"}
	
	docker run -d -v "/d/code1/prometheus/grafana:/var/lib/grafana" -p 3000:3000 grafana/grafana-oss:8.5.2 
	
	host.docker.internal
		import dashboard 
	
		search for logback_events_total
		logback_events_total{level="warn"}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Docker basics

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Kubernetes overview and cloud deployment
https://pitstop.manageengine.com/portal/en/kb/articles/how-to-connect-azure-kubernetes-service-aks-cluster#Login_to_the_Azure_account 

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------


Kafka

--------------------------------------------------------------------------------

Introduction: 
	Apache Kafka 
		open-source distributed event streaming platform 
		initially developed by LinkedIn 
			later open-sourced through the Apache Software Foundation. 
		Designed to handle 
			real-time data streams efficiently 
			widely used in 
				event-driven architectures, 
				microservices, 
				data pipelines, and 
				log aggregation systems. 
		Kafka provides 
			high throughput, 
			fault tolerance, and 
			horizontal scalability.

Architecture: 
	Kafka operates as a 
		distributed system of brokers (servers). 
		Data is organized into 
			topics, 
				further divided into partitions. 
					Each partition 
						acts as a commit log, 
						with messages being appended in order. 
		Producers send data to Kafka brokers, 
			which store it across multiple brokers for fault tolerance. 
		Consumers read the messages in a fault-tolerant manner. 
Kafka's main architectural components are:

	Producers: 
		Applications that send messages (events) to Kafka topics.
	Brokers: 
		Kafka servers 
			store and serve the messages.
	Consumers: 
		Applications that subscribe to topics to consume messages.
	Zookeeper: 
		A centralized service 
			manages the metadata and health of Kafka brokers 
				
	Connect: 
		Used to integrate Kafka with 
			external systems like 
				databases or file systems.
	Streams: 
		Allows complex stream processing 
			(real-time data transformation) directly within Kafka.
Key Concepts:

	Topics and Partitions: 
		Data is organized into topics
			subdivided into partitions for scalability. 
		Each message within a partition 
			assigned a sequential ID called an offset. 
		Consumers 
			can track which messages they’ve processed 
				using these offsets.

	Producers and Consumers: 
		Kafka producers 
			applications or 
			services 
				write data to Kafka topics. 
		Consumers 
			subscribe to one or more topics 
			process the incoming messages. 
		Kafka allows consumers to belong to a consumer group, 
			ensuring that each message is consumed by only one member of the group, 
			promoting parallelism.

	Message Retention: 
		Kafka 
			retains messages 
				based on configurable time or 
				space policies, 
					ideal for 
						both real-time and 
						historical message processing. 
			Retention settings 
				messages persist for future consumers or auditing purposes.

	Durability and Fault Tolerance: 
		Kafka replicates partitions 
			across multiple brokers. 
			Each partition has a leader, 
				handles all reads and writes
				one or more followers 
					replicate the leader's data. 
		If the leader fails
			one of the followers is promoted to leader, 
			ensuring data availability.

Data Flow in Kafka:

	Producers 
		publish records 
			to a specific topic.
	The message is stored in partitions, 
		with replication for redundancy.
	Consumers subscribe to topics, 
		reading records sequentially 
			by maintaining offsets.
	Kafka 
		keeps track of 
			consumer group offsets, 
			enabling recovery in case of failure.
	Kafka Use Cases: 
		Kafka excels in various real-time data streaming applications:

			Log Aggregation: 
				Kafka is commonly used to collect logs from distributed services and aggregate them for centralized analysis.
			Event Sourcing: 
				In event-driven architectures, Kafka captures every change in state as an immutable event log.
			Stream Processing: 
				Kafka Streams API allows real-time processing and analysis of data as it moves through Kafka topics.
			Messaging Queue: 
				Kafka’s consumer group mechanism allows it to act as a messaging system with built-in fault tolerance and high throughput.
			Data Pipelines: 
				Kafka is widely used for building scalable and fault-tolerant pipelines that stream data between systems like databases, analytics tools, and monitoring platforms.
Kafka Advantages:

	Scalability: 
		Kafka scales horizontally by adding more brokers and partitioning topics.
	Fault Tolerance: 
		Data is replicated across brokers to ensure fault tolerance, even in the event of server or network failures.
	Performance: 
		Kafka delivers high throughput for both publishing and subscribing, making it suitable for applications needing to process millions of events per second.
	Durability: 
		Kafka retains messages on disk, allowing long-term persistence of data for later reprocessing.
Kafka Streams and Connect:

	Kafka Streams: 
		stream processing library 
			allows applications to 
				process and 
				transform 
					data within Kafka itself. 
		It supports complex operations like 
			filtering, 
			joining, and 
			aggregations.
	Kafka Connect: 
		A tool to easily integrate 
			Kafka 
				with external systems, 
					such as 
						databases, 
						key-value stores, 
						search indexes, and 
						file systems. 
			It provides 
				built-in connectors 
					for popular data sources and sinks.
	Kafka vs Traditional Messaging Systems: 
		Unlike traditional messaging systems like 
			RabbitMQ or 
			ActiveMQ, 
				Kafka is designed for 
					high-throughput, 
					real-time data streaming 
						rather than transactional messaging. 
			Kafka allows 
				each message to be processed 
					multiple times by different consumers 
						(event streaming model) 
						rather than once (messaging queue model). 
			Additionally, 
				Kafka provides stronger 
					durability guarantees with its 
						log-based storage mechanism.

Challenges with Kafka:

	Complexity: 
		Managing and configuring Kafka in large-scale environments can be complex due to the need for broker replication, partitioning, and fault-tolerant design.
	Zookeeper Dependency: 
		Zookeeper, a critical component for managing brokers, adds an extra layer of complexity, though Kafka is moving towards removing this dependency in future versions.
	Message Ordering: 
		While Kafka guarantees message ordering within a partition, it does not guarantee global ordering across partitions.
	Kafka in Microservices: 
		Kafka is often used in microservices architectures for event-driven communication. Each service can produce and consume events independently, improving decoupling. Kafka’s distributed nature ensures scalability, while its message retention policies allow replaying past events, crucial for state recovery and debugging.
		
		
Spring boot: 
	changes in 
		pom.xml 
		application.yml 
		
	/d/PraiseTheLord/HSBGInfotech/Others/kafka-stack-docker-compose	
		https://github.com/conduktor/kafka-stack-docker-compose
		
		
		


	--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

https://github.com/amrutprabhu/grafana-prometheus
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------



--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
